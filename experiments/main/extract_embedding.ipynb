{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2b194d-b681-46b8-a3a8-443d313cbb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import gensim\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tokenizers import Tokenizer, decoders, pre_tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08fcb108-1551-4129-a6cd-b4f064f7bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ch = Path(\"../dataset/ASPEC-JC/train/filtered_ch.txt\")\n",
    "train_jp = Path(\"../dataset/ASPEC-JC/train/filtered_jp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14dbd678-ba8a-4a3b-8871-86af1ba0eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_ch = Path(\"../tokenizer/tokenizer_sentencepiece_ch.json\")\n",
    "tokenizer_jp = Path(\"../tokenizer/tokenizer_sentencepiece_jp.json\")\n",
    "\n",
    "tokenizer_ch = Tokenizer.from_file(str(tokenizer_ch))\n",
    "tokenizer_jp = Tokenizer.from_file(str(tokenizer_jp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462c08a5-85bd-4786-8d30-195e41137e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n",
      "32000\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_ch.get_vocab_size())\n",
    "print(tokenizer_jp.get_vocab_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf4c7b-f76e-4b49-9e59-36a5e0bb05ef",
   "metadata": {},
   "source": [
    "# Tokenize raw sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea04b4e-f0e3-4263-b7be-d07aa0c017b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_path = Path(\"../tokenized_sentences/\")\n",
    "tokenized_ch_path = tokenized_path / \"ch.txt\"\n",
    "tokenized_jp_path = tokenized_path / \"jp.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6914fb1-3842-4dd4-a68d-0b5cd2278430",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenized_ch_path.exists():\n",
    "    with open(tokenized_ch_path, \"rb\") as f:\n",
    "        ch_texts = pickle.load(f)\n",
    "else:\n",
    "    with open(train_ch) as f:\n",
    "        ch_texts = [tokenizer_ch.encode(line).tokens[1:-1] for line in f.readlines()]\n",
    "    \n",
    "    with open(tokenized_ch_path, \"wb\") as f:\n",
    "         pickle.dump(ch_texts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed81a83-cd48-4c4c-b786-0e2a69228597",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenized_jp_path.exists():\n",
    "    with open(tokenized_jp_path, \"rb\") as f:\n",
    "        jp_texts = pickle.load(f)\n",
    "else:\n",
    "    with open(train_jp) as f:\n",
    "        jp_texts = [tokenizer_jp.encode(line).tokens[1:-1] for line in f.readlines()]\n",
    "    \n",
    "    with open(tokenized_jp_path, \"wb\") as f:\n",
    "         pickle.dump(jp_texts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c8141-5f11-4066-9ece-136b84c2935e",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d6eaccd-7986-426a-9fe2-cf0421965d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocab, embedding, map_func=None):\n",
    "    \"\"\"\n",
    "    vocab = vocabulary from tokenizer, input=[(voc, index)]\n",
    "    embedding = word2vec embedding\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for word in vocab.keys():\n",
    "        if map_func:\n",
    "            word = map_func(word)\n",
    "        try:\n",
    "            if embedding[word] is not None:\n",
    "                count += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(f\"{count / len(vocab):.0%} ({count}/{len(vocab)}) is covered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de65373-ec20-4cc6-b396-2dd8bb257512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix(vocab, embedding, map_func=None):\n",
    "    \"\"\"\n",
    "    vocab = vocabulary from tokenizer, input=[(voc, index)]\n",
    "    embedding = word2vec embedding\n",
    "    \"\"\"\n",
    "    embed_matrix = np.zeros((len(vocab), 300))\n",
    "    \n",
    "    for word, i in vocab.items():\n",
    "        if map_func:\n",
    "            word = map_func(word)\n",
    "            \n",
    "        if word in embedding:\n",
    "            embed_matrix[i] = embedding[word]\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f248f750-68fe-40b9-9cf3-d6ff8084ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word2vec(tokenized_corpus, vector_size=300, max_vocab_size=32000, rule=None):\n",
    "    return Word2Vec(\n",
    "        tokenized_corpus,\n",
    "        vector_size=vector_size,\n",
    "        max_vocab_size=max_vocab_size,\n",
    "        sg=1,\n",
    "        hs=0,\n",
    "        negative=5,\n",
    "        workers=32,\n",
    "        min_count=5,\n",
    "        trim_rule=rule,\n",
    "        epochs=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22badf0-6ed5-482a-940a-fbccf7e539aa",
   "metadata": {},
   "source": [
    "# Train Semantic Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "629f5172-103d-4ce0-9e24-ec3fb6cecac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# if any chinese + japanese\n",
    "reg = re.compile(r'[\\u3040-\\u30ff\\u3400-\\u4dbf\\u4e00-\\u9fff\\uf900-\\ufaff\\uff66-\\uff9f]')\n",
    "\n",
    "def semantic_rule(word, count, min_count):\n",
    "    if reg.search(word):\n",
    "        return gensim.utils.RULE_DEFAULT\n",
    "    else:\n",
    "        return gensim.utils.RULE_DISCARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4473cfe1-7f25-4ba6-9692-2beec7bd0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_path = Path(\"../word2vec/\")\n",
    "semantic_path = word2vec_path / \"semantic/\"\n",
    "semantic_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ch_semantic_path = semantic_path / \"ch_word2vec\"\n",
    "jp_semantic_path = semantic_path / \"jp_word2vec\"\n",
    "\n",
    "ch_semantic_embedding_path = semantic_path / \"ch_embedding.npy\"\n",
    "jp_semantic_embedding_path = semantic_path / \"jp_embedding.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37c9bc4-f447-4ad4-a0e2-5c13d100c578",
   "metadata": {},
   "source": [
    "## Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f68ff4b4-37d8-4c7f-a38d-6fe8e7716b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ch_semantic_path.exists():\n",
    "    ch_model = Word2Vec.load(str(ch_semantic_path))\n",
    "else:\n",
    "    ch_model = build_word2vec(ch_texts, rule=semantic_rule)\n",
    "    ch_model.save(str(ch_semantic_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af1a24d1-5625-4cd4-a4db-e7fc73e71e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27382, 300)\n"
     ]
    }
   ],
   "source": [
    "print(ch_model.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e26c1e8f-517d-42e3-b54b-138cb464a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86% (27382/32000) is covered.\n"
     ]
    }
   ],
   "source": [
    "check_coverage(tokenizer_ch.get_vocab(), ch_model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ea67933-80f2-4409-8379-2738fbd9fd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ch_semantic_embedding_path.exists():\n",
    "    ch_semantic_embedding = np.load(ch_semantic_embedding_path)\n",
    "else:\n",
    "    ch_semantic_embedding = build_embedding_matrix(tokenizer_ch.get_vocab(), ch_model.wv)\n",
    "    np.save(ch_semantic_embedding_path, ch_semantic_embedding)\n",
    "\n",
    "ch_semantic_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafb9ec-72ef-45a5-ac83-ca491b3688e9",
   "metadata": {},
   "source": [
    "## Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd9e33aa-9df9-44a1-b5c7-16640cdbb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "if jp_semantic_path.exists():\n",
    "    jp_model = Word2Vec.load(str(jp_semantic_path))\n",
    "else:\n",
    "    jp_model = build_word2vec(jp_texts, rule=semantic_rule)\n",
    "    jp_model.save(str(jp_semantic_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a478828-e3e1-4415-a21a-4c28f51be22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28313, 300)\n"
     ]
    }
   ],
   "source": [
    "print(jp_model.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2776bbd-90d5-4b7a-8f09-237669abb6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88% (28313/32000) is covered.\n"
     ]
    }
   ],
   "source": [
    "check_coverage(tokenizer_jp.get_vocab(), jp_model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "647691ae-db13-40b9-8a03-ed7748894827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if jp_semantic_embedding_path.exists():\n",
    "    jp_semantic_embedding = np.load(jp_semantic_embedding_path)\n",
    "else:\n",
    "    jp_semantic_embedding = build_embedding_matrix(tokenizer_jp.get_vocab(), jp_model.wv)\n",
    "    np.save(jp_semantic_embedding_path, jp_semantic_embedding)\n",
    "\n",
    "jp_semantic_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0b44e-b12b-4a19-9d0b-73078eeb0e1b",
   "metadata": {},
   "source": [
    "# Tokenize Phonetic Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b961957-0d69-4a94-ba3f-1af24d31d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ch_phonetic_path = tokenized_path / \"chp.txt\"\n",
    "tokenized_jp_phonetic_path = tokenized_path / \"jpp.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68081d0-6798-47e7-8947-f2b72dc29725",
   "metadata": {},
   "source": [
    "## Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74efe68f-9ab3-44eb-981f-69b8a2ff37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonmapper import hanzi\n",
    "\n",
    "def to_zhuyin(word):\n",
    "    try:\n",
    "        word = hanzi.to_zhuyin(word)\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        return word\n",
    "\n",
    "def generate_ch_phonetic_sentences(ch_texts):\n",
    "    return [[to_zhuyin(s) for s in line] for line in ch_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e2884e9-90df-41e3-a72e-8df28ebd64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenized_ch_phonetic_path.exists():\n",
    "    with open(tokenized_ch_phonetic_path, 'rb') as f:\n",
    "        chp_texts = pickle.load(f)\n",
    "else:\n",
    "    chp_texts = generate_ch_phonetic_sentences(ch_texts)\n",
    "    with open(tokenized_ch_phonetic_path, 'wb') as f:\n",
    "        pickle.dump(chp_texts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cc30f6-5889-4308-8280-3e0588ae14a2",
   "metadata": {},
   "source": [
    "## Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ff153c6-6d62-4e1c-9bdc-57452fdf2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykakasi\n",
    "\n",
    "kks = pykakasi.kakasi()\n",
    "\n",
    "def to_hira(kanji):\n",
    "    return \"\".join([item[\"hira\"] for item in kks.convert(kanji)])\n",
    "\n",
    "def generate_jp_phonetic_sentences(jp_texts):\n",
    "    return [[to_hira(s) for s in line] for line in jp_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b226986-bfa5-4e01-866f-88be3d515cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenized_jp_phonetic_path.exists():\n",
    "    with open(tokenized_jp_phonetic_path, 'rb') as f:\n",
    "        jpp_texts = pickle.load(f)\n",
    "else:\n",
    "    jpp_texts = generate_jp_phonetic_sentences(jp_texts)\n",
    "    with open(tokenized_jp_phonetic_path, 'wb') as f:\n",
    "        pickle.dump(jpp_texts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b3ea7-fd37-4e8e-9f1d-426a90ede646",
   "metadata": {},
   "source": [
    "# Train Phonetic Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53bd9881-1691-4768-b49d-021b42b4b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonetic_path = word2vec_path / \"phonetic/\"\n",
    "phonetic_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ch_phonetic_path = phonetic_path / \"chp_word2vec\"\n",
    "jp_phonetic_path = phonetic_path / \"jpp_word2vec\"\n",
    "\n",
    "ch_phonetic_embedding_path = phonetic_path / \"chp_embedding.npy\"\n",
    "jp_phonetic_embedding_path = phonetic_path / \"jpp_embedding.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4f165f7-e1ae-4e31-ae82-cf898cb7293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/16027450/is-there-a-way-to-know-whether-a-unicode-string-contains-any-chinese-japanese-ch\n",
    "import unicodedata\n",
    "\n",
    "def has_zhuyin(s):\n",
    "    for c in s:\n",
    "        try:\n",
    "            if \"BOPOMOFO\" in unicodedata.name(c):\n",
    "                return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "def has_hira(s):\n",
    "    for c in s:\n",
    "        try:\n",
    "            if \"HIRAGANA\" in unicodedata.name(c):\n",
    "                return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "def phonetic_rule(word, count, min_count):\n",
    "    if has_zhuyin(word) or has_hira(word):\n",
    "        return gensim.utils.RULE_DEFAULT\n",
    "    else:\n",
    "        return gensim.utils.RULE_DISCARD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516c2ee-9a09-4347-8a51-ed3f3ae77d59",
   "metadata": {},
   "source": [
    "## Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca6de057-0bcb-45f7-a1fa-b6863c9b764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ch_phonetic_path.exists():\n",
    "    chp_model = Word2Vec.load(str(ch_phonetic_path))\n",
    "else:\n",
    "    chp_model = build_word2vec(chp_texts, rule=phonetic_rule)\n",
    "    chp_model.save(str(ch_phonetic_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e2549de-8f5c-4b01-8e52-6ad00466c7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25321, 300)\n"
     ]
    }
   ],
   "source": [
    "print(chp_model.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30ec35aa-b973-4e3c-ba4d-a330132783bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94% (30009/32000) is covered.\n"
     ]
    }
   ],
   "source": [
    "check_coverage(tokenizer_ch.get_vocab(), chp_model.wv, map_func=to_zhuyin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8db7772-d564-472b-b351-25fcdfc73042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ch_phonetic_embedding_path.exists():\n",
    "    ch_phonetic_embedding = np.load(ch_phonetic_embedding_path)\n",
    "else:\n",
    "    ch_phonetic_embedding = build_embedding_matrix(tokenizer_ch.get_vocab(), chp_model.wv, map_func=to_zhuyin)\n",
    "    np.save(ch_phonetic_embedding_path, ch_phonetic_embedding)\n",
    "\n",
    "ch_phonetic_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6161a-5db7-4bd7-9d36-ec507eb2d7cd",
   "metadata": {},
   "source": [
    "## Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9501461c-efbd-437f-9ec3-b8a27578ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if jp_phonetic_path.exists():\n",
    "    jpp_model = Word2Vec.load(str(jp_phonetic_path))\n",
    "else:\n",
    "    jpp_model = build_word2vec(jpp_texts, rule=phonetic_rule)\n",
    "    jpp_model.save(str(jp_phonetic_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "195deb9f-340f-4035-837a-99f0c3cd1f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24371, 300)\n"
     ]
    }
   ],
   "source": [
    "print(jpp_model.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "425e6a7f-1933-412d-9982-9628834898bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91% (29080/32000) is covered.\n"
     ]
    }
   ],
   "source": [
    "check_coverage(tokenizer_jp.get_vocab(), jpp_model.wv, map_func=to_hira)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a437cefd-2944-488f-b446-32419bc23693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 300)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if jp_phonetic_embedding_path.exists():\n",
    "    jp_phonetic_embedding = np.load(jp_phonetic_embedding_path)\n",
    "else:\n",
    "    jp_phonetic_embedding = build_embedding_matrix(tokenizer_jp.get_vocab(), jpp_model.wv, map_func=to_hira)\n",
    "    np.save(jp_phonetic_embedding_path, jp_phonetic_embedding)\n",
    "\n",
    "jp_phonetic_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad565ee3-2c03-4305-8238-c87ab10093c0",
   "metadata": {},
   "source": [
    "# Concatenate Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "059e493e-ab2a-484f-945c-3dc9f0bbfbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 300)\n",
      "(32000, 300)\n",
      "(32000, 300)\n",
      "(32000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(ch_semantic_embedding.shape)\n",
    "print(jp_semantic_embedding.shape)\n",
    "\n",
    "print(ch_phonetic_embedding.shape)\n",
    "print(jp_phonetic_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91cafbf1-c828-44dc-8305-8d5390a86a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 600)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_embedding = np.concatenate([ch_semantic_embedding, ch_phonetic_embedding], axis=1)\n",
    "ch_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5e23634-7ac1-4ea0-9f1e-ade3eb7daa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 600)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp_embedding = np.concatenate([jp_semantic_embedding, jp_phonetic_embedding], axis=1)\n",
    "jp_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f820d610-8a43-4bb0-b5ce-b53273b60eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(word2vec_path / \"ch-embedding-concat.npy\", ch_embedding)\n",
    "np.save(word2vec_path / \"jp-embedding-concat.npy\", jp_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a453db1-7d13-43f8-b7b1-592ea5937e27",
   "metadata": {},
   "source": [
    "# Meta Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a94b9ef-b1b9-4180-bc13-a3b0fbe589b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7c74ec3-b3fb-4dfa-863f-49dd8d73da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 300)\n",
      "(32000, 300)\n",
      "(32000, 300)\n",
      "(32000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(ch_semantic_embedding.shape)\n",
    "print(jp_semantic_embedding.shape)\n",
    "\n",
    "print(ch_phonetic_embedding.shape)\n",
    "print(jp_phonetic_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e6c44ad-77c8-4fbd-a9a5-338199878549",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_meta_embedding = np.mean(\n",
    "    [(2 - (beta * 2)) * ch_semantic_embedding, (beta * 2) * ch_phonetic_embedding],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5cddfc10-2675-4027-bf9c-ffa5e5f3b00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 300)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_meta_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4255c13-65d9-4f0f-b68e-a6fb02659b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_meta_embedding = np.mean(\n",
    "    [(2 - (beta * 2)) * jp_semantic_embedding, (beta * 2) * jp_phonetic_embedding],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4039ddbf-6ca7-4d0b-b200-94e828372413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 300)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp_meta_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5526c294-2ccc-4bb3-8810-c89159e04769",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(word2vec_path / f\"ch-embedding-meta-{beta=}.npy\", ch_meta_embedding)\n",
    "np.save(word2vec_path / f\"jp-embedding-meta-{beta=}.npy\", jp_meta_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
