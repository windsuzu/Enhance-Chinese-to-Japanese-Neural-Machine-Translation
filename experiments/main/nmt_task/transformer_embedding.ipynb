{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import built-in Python libs\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "import heapq\n",
    "\n",
    "# Import data science libs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import deep learning libs\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import weights & bias\n",
    "import wandb\n",
    "\n",
    "# Import data preprocessing libs\n",
    "from tokenizers import Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_path = Path.cwd().parent / \"utils\"\n",
    "sys.path.append(str(utils_path))\n",
    "from custom_tokenizer import load_jieba_tokenizer, load_janome_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = 1     # 0 - sentencepiece, 1 - language specific\r\n",
    "\r\n",
    "job_name = [\"transformer_sentencepiece_ch2jp\", \"transformer_language_specific_ch2jp\"]\r\n",
    "\r\n",
    "tokenizer_job = [\"sentencepiece\", \"language_specific\"]\r\n",
    "ch_tokenizer_job = [\"ch_tokenizer.json\", \"jieba_tokenizer.json\"]\r\n",
    "jp_tokenizer_job = [\"jp_tokenizer.json\", \"janome_tokenizer.json\"]\r\n",
    "embedding_job = [\"sentencepiece_embedding\", \"language_specific_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 0\r\n",
    "method_name = [\"semantic-full\", \"phonetic-full\", \"meta-full\", \"concat\"]\r\n",
    "\r\n",
    "ch_embedding_method = [\r\n",
    "    \"ch_embedding.npy\",\r\n",
    "    \"chp_embedding.npy\",\r\n",
    "    \"ch_meta_embedding.npy\",\r\n",
    "    \"ch_concat_embedding.npy\",\r\n",
    "]\r\n",
    "\r\n",
    "jp_embedding_method = [\r\n",
    "    \"jp_embedding.npy\",\r\n",
    "    \"jpp_embedding.npy\",\r\n",
    "    \"jp_meta_embedding.npy\",\r\n",
    "    \"jp_concat_embedding.npy\",\r\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config and WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\r\n",
    "    \"enc_layers\": 3,\r\n",
    "    \"dec_layers\": 3,\r\n",
    "    \"enc_heads\": 6,\r\n",
    "    \"dec_heads\": 6,\r\n",
    "    \"enc_pf_dim\": 512,\r\n",
    "    \"dec_pf_dim\": 512,\r\n",
    "    \"enc_dropout\": 0.1,\r\n",
    "    \"dec_dropout\": 0.1,\r\n",
    "    \"hid_dim\": (300 if method != 3 else 600),\r\n",
    "    \"lr\": 5e-4,\r\n",
    "    \"batch_size\": 64,\r\n",
    "    \"num_workers\": 0,\r\n",
    "    \"precision\": 32,\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: windsuzu (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": "\n                Tracking run with wandb version 0.10.28<br/>\n                Syncing run <strong style=\"color:#cdcd00\">copper-fog-379</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/windsuzu/phonetic-translation\" target=\"_blank\">https://wandb.ai/windsuzu/phonetic-translation</a><br/>\n                Run page: <a href=\"https://wandb.ai/windsuzu/phonetic-translation/runs/3fvevjqy\" target=\"_blank\">https://wandb.ai/windsuzu/phonetic-translation/runs/3fvevjqy</a><br/>\n                Run data is saved locally in <code>d:\\Projects\\phonetics-in-chinese-japanese-machine-translation\\experiments\\main\\ch2jp\\wandb\\run-20210530_005102-3fvevjqy</code><br/><br/>\n            ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\r\n",
    "    project=\"phonetic-translation\",\r\n",
    "    entity=\"windsuzu\",\r\n",
    "    group=\"experiments\",\r\n",
    "    # job_type=job_name[job] + \"-\" + method_name[method],\r\n",
    "    job_type=\"full_model_prediction\",\r\n",
    "    config=config,\r\n",
    "    reinit=True,\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Datasets, Tokenizers, Embedding, DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Downloading large artifact filtered_train:latest, 99.47MB. 2 files... Done. 0:0:0\n"
     ]
    }
   ],
   "source": [
    "train_data_art = run.use_artifact(\"filtered_train:latest\")\r\n",
    "train_data_dir = train_data_art.download()\r\n",
    "\r\n",
    "dev_data_art = run.use_artifact(\"dev:latest\")\r\n",
    "dev_data_dir = dev_data_art.download()\r\n",
    "\r\n",
    "test_data_art = run.use_artifact(\"test:latest\")\r\n",
    "test_data_dir = test_data_art.download()\r\n",
    "\r\n",
    "data_dir = {\r\n",
    "    \"train\": train_data_dir,\r\n",
    "    \"dev\": dev_data_dir,\r\n",
    "    \"test\": test_data_dir,\r\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_art = run.use_artifact(f\"{tokenizer_job[job]}:latest\")\n",
    "tokenizer_dir = tokenizer_art.download()\n",
    "\n",
    "src_tokenizer_dir = Path(tokenizer_dir) / ch_tokenizer_job[job]\n",
    "trg_tokenizer_dir = Path(tokenizer_dir) / jp_tokenizer_job[job]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Downloading large artifact language_specific_embedding:latest, 732.42MB. 8 files... Done. 0:0:0\n"
     ]
    }
   ],
   "source": [
    "embedding_art = run.use_artifact(f\"{embedding_job[job]}:latest\")\n",
    "embedding_dir = embedding_art.download()\n",
    "\n",
    "ch_embedding_dir = Path(embedding_dir) / ch_embedding_method[method]\n",
    "jp_embedding_dir = Path(embedding_dir) / jp_embedding_method[method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_embedding = np.load(Path(ch_embedding_dir))\n",
    "trg_embedding = np.load(Path(jp_embedding_dir))\n",
    "\n",
    "src_embedding = torch.FloatTensor(src_embedding)\n",
    "trg_embedding = torch.FloatTensor(trg_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32000, 300])\n",
      "torch.Size([32000, 300])\n"
     ]
    }
   ],
   "source": [
    "print(src_embedding.shape)\n",
    "print(trg_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentencePieceDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        src_tokenizer_dir,\n",
    "        trg_tokenizer_dir,\n",
    "        batch_size=128,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        job=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.src_tokenizer_dir = src_tokenizer_dir\n",
    "        self.trg_tokenizer_dir = trg_tokenizer_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.job = job\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.src_tokenizer = self._load_tokenizer(self.src_tokenizer_dir)\n",
    "        self.trg_tokenizer = self._load_tokenizer(self.trg_tokenizer_dir)\n",
    "\n",
    "        if stage == \"fit\":\n",
    "            self.train_set = self._data_preprocess(self.data_dir[\"train\"])\n",
    "            self.val_set = self._data_preprocess(self.data_dir[\"dev\"])\n",
    "\n",
    "        if stage == \"test\":\n",
    "            self.test_set = self._data_preprocess(self.data_dir[\"test\"])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_set,\n",
    "            self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            collate_fn=self._data_batching_fn,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_set,\n",
    "            self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            collate_fn=self._data_batching_fn,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_set,\n",
    "            self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            collate_fn=self._data_batching_fn,\n",
    "        )\n",
    "\n",
    "    def _read_data_array(self, data_dir):\n",
    "        with open(data_dir, encoding=\"utf8\") as f:\n",
    "            arr = f.readlines()\n",
    "        return arr\n",
    "\n",
    "    def _load_tokenizer(self, tokenizer_dir):\n",
    "        if self.job == 0:\n",
    "            return Tokenizer.from_file(str(tokenizer_dir))\n",
    "        else:\n",
    "            return (\n",
    "                load_jieba_tokenizer(tokenizer_dir)\n",
    "                if \"jieba\" in str(tokenizer_dir)\n",
    "                else load_janome_tokenizer(tokenizer_dir)\n",
    "            )\n",
    "\n",
    "    def _data_preprocess(self, data_dir):\n",
    "        src_txt = self._read_data_array(Path(data_dir) / \"ch.txt\")\n",
    "        trg_txt = self._read_data_array(Path(data_dir) / \"jp.txt\")\n",
    "        parallel_txt = np.array(list(zip(src_txt, trg_txt)))\n",
    "        return parallel_txt\n",
    "\n",
    "    def _data_batching_fn(self, data_batch):\n",
    "        data_batch = np.array(data_batch)  # shape=(batch_size, 2=src+trg)\n",
    "\n",
    "        src_batch = data_batch[:, 0]  # shape=(batch_size, )\n",
    "        trg_batch = data_batch[:, 1]  # shape=(batch_size, )\n",
    "\n",
    "        # src_batch=(batch_size, longest_sentence)\n",
    "        # trg_batch=(batch_size, longest_sentence)\n",
    "        src_batch = self.src_tokenizer.encode_batch(src_batch)\n",
    "        trg_batch = self.trg_tokenizer.encode_batch(trg_batch)\n",
    "\n",
    "        # We have to sort the batch by their non-padded lengths in descending order,\n",
    "        # because the descending order can help in `nn.utils.rnn.pack_padded_sequence()`,\n",
    "        # which it will help us ignoring the <pad> in training rnn.\n",
    "        # https://meetonfriday.com/posts/4d6a906a\n",
    "        src_batch, trg_batch = zip(\n",
    "            *sorted(\n",
    "                zip(src_batch, trg_batch),\n",
    "                key=lambda x: sum(x[0].attention_mask),\n",
    "                reverse=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return src_batch, trg_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm = SentencePieceDataModule(\n",
    "    data_dir,\n",
    "    src_tokenizer_dir,\n",
    "    trg_tokenizer_dir,\n",
    "    config[\"batch_size\"],\n",
    "    config[\"num_workers\"],\n",
    "    job=job\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000 32000\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "input_dim = dm.src_tokenizer.get_vocab_size()\n",
    "output_dim = dm.trg_tokenizer.get_vocab_size()\n",
    "print(input_dim, output_dim)\n",
    "\n",
    "src_pad_idx = dm.src_tokenizer.token_to_id(\"[PAD]\")\n",
    "print(src_pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Jay\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.787 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Encoding(num_tokens=105, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]) ['[BOS]', '日本', '从', '世界', '各国', '进口', '酱油', '等', '的', '各种', '调', '料', ',', '但', '公', '知', '的', '是', '在', '制造', '过程', '中', '致癌性', '物质', '的', '氯', '丙', '醇', '类', '作为', '副产品', '生成', '3', '-', '氯', '-', '1', ',', '2', '-', '丙', '二醇', '(', '3', '-', 'MCP', 'D', ')', '、', '1', ',', '3', '-', '二氯', '-', '2', '-', '丙', '醇', '(', '1', ',', '3', '-', 'D', 'CP', ')', '、', '2', '-', '氯', '-', '1', ',', '3', '-', '丙', '二醇', '(', '2', '-', 'MCP', 'D', ')', '以及', '2', ',', '3', '-', '二氯', '-', '1', '丙', '醇', '(', '2', ',', '3', '-', 'D', 'CP', ')', '。', '\\n', '[EOS]']\n",
      "\n",
      "64 Encoding(num_tokens=114, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]) ['[BOS]', '日本', 'へ', 'は', '世界', '各国', 'から', '醤油', 'など', 'の', '種々', 'の', '調味', '料', 'が', '輸入', 'さ', 'れ', 'て', 'いる', 'が', ',', '製造', '過程', '中', 'で', '発癌', '性', '物質', 'の', 'クロロ', 'プロパノール', '類', 'が', '副産物', 'として', '3', '−', 'クロ', 'ロ', '−', '1', ',', '2', '−', 'プロパン', 'ジオール', '(', '3', '−', 'MCP', 'D', '),', '1', ',', '3', '−', 'ジクロロ', '−', '2', '−', 'プロパノール', '(', '1', ',', '3', '−', 'DCP', '),', '2', '−', 'クロ', 'ロ', '−', '1', ',', '3', '−', 'プロパン', 'ジオール', '(', '2', '−', 'MCP', 'D', ')', 'および', '2', ',', '3', '−', 'ジクロロ', '−', '1', 'プロパノール', '(', '2', ',', '3', '−', 'DCP', ')', 'が', '生成', 'さ', 'れる', 'こと', 'が', '知ら', 'れ', 'て', 'いる', '。', '[EOS]']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for src, trg in dm.test_dataloader():\n",
    "    print(len(src), src[i], src[i].tokens)\n",
    "    print()\n",
    "    print(len(trg), trg[i], trg[i].tokens)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Lightning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, max_len=250):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding.from_pretrained(src_embedding)\n",
    "        self.pos_embedding = nn.Embedding(max_len, hid_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(hid_dim, n_heads, pf_dim, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.register_buffer(\"scale\", torch.sqrt(torch.FloatTensor([hid_dim])))\n",
    "\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        # src      = [batch_size, src_len]\n",
    "        # src_mask = [batch_size, 1, 1, src_len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).type_as(src)\n",
    "        # pos = [batch_size, src_len]\n",
    "        \n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        # src = [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        # src = [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        # src     = [batch_size, src_len, hid_dim]\n",
    "        # src_mask = [batch_size, 1, 1, src_len]\n",
    "        \n",
    "        # self attention\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        \n",
    "        # dropout, residual connection, layer norm\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        # src = [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        \n",
    "        # positionwise feedforward\n",
    "        _src = self.positionwise_feedforward(src)\n",
    "        \n",
    "        # dropout, residual connection, layer norm\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        # src = [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.register_buffer(\"scale\", torch.sqrt(torch.FloatTensor([hid_dim])))\n",
    "\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "\n",
    "        # query = [batch_size, query_len, hid_dim]\n",
    "        # key = [batch_size, key_len, hid_dim]\n",
    "        # value = [batch_size, value_len, hid_dim]\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        \n",
    "        # Q = [batch_size, query_len, hid_dim]\n",
    "        # K = [batch_size, key_len, hid_dim]\n",
    "        # V = [batch_size, value_len, hid_dim]\n",
    "        \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        # Q = [batch_size, n_heads, query_len, head_dim]\n",
    "        # K = [batch_size, n_heads, key_len, head_dim]\n",
    "        # V = [batch_size, n_heads, value_len, head_dim]\n",
    "        \n",
    "\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        # energy = [batch_size, n_heads, query_len, key_len]\n",
    "        \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "        # attention = [batch_size, n_heads, query_len, key_len]\n",
    "        \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        # x = [batch_size, n_heads, query_len, head_dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        # x = [batch_size, query_len, n_heads, head_dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        # x = [batch_size, query_len, hid_dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        # x = [batch_size, query_len, hid_dim]\n",
    "        \n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position-wise Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = [batch_size, seq_len, hid_dim]\n",
    "        \n",
    "        \n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        # x = [batch_size, seq_len, pf_dim]\n",
    "        \n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "        # x = [batch_size, seq_len, hid_dim]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, output_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, max_len=250\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tok_embedding = nn.Embedding.from_pretrained(trg_embedding)\n",
    "        self.pos_embedding = nn.Embedding(max_len, hid_dim)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [DecoderLayer(hid_dim, n_heads, pf_dim, dropout) for _ in range(n_layers)]\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.register_buffer(\"scale\", torch.sqrt(torch.FloatTensor([hid_dim])))\n",
    "        \n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        # trg = [batch_size, trg_len]\n",
    "        # enc_src = [batch_size, src_len, hid_dim]\n",
    "        # trg_mask = [batch_size, 1, trg_len, trg_len]\n",
    "        # src_mask = [batch_size, 1, 1, src_len]\n",
    "        \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).type_as(trg)\n",
    "        # pos = [batch_size, trg_len]\n",
    "        \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        # trg = [batch_size, trg_len, hid_dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        # trg = [batch_size, trg_len, hid_dim]\n",
    "        # attention = [batch_size, n heads, trg_len, src_len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        # output = [batch_size, trg_len, output_dim]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        \n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout)\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        # trg = [batch_size, trg_len, hid_dim]\n",
    "        # enc_src = [batch_size, src_len, hid_dim]\n",
    "        # trg_mask = [batch_size, 1, trg_len, trg_len]\n",
    "        # src_mask = [batch_size, 1, 1, src_len]\n",
    "        \n",
    "        # self attention\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        # dropout, residual connection and layer norm\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "         \n",
    "        # trg = [batch_size, trg_len, hid_dim]\n",
    "        # ====================================\n",
    "        \n",
    "        # encoder attention\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        # dropout, residual connection and layer norm\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        \n",
    "        # trg = [batch_size, trg_len, hid_dim]\n",
    "        # ====================================\n",
    "        \n",
    "        \n",
    "        # positionwise feedforward\n",
    "        _trg = self.positionwise_feedforward(trg)\n",
    "        \n",
    "        # dropout, residual and layer norm\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        \n",
    "        # trg = [batch_size, trg_len, hid_dim]\n",
    "        # ====================================\n",
    "        \n",
    "        # attention = [batch_size, n_heads, trg_len, src_len]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, output_dim, trg_tokenizer, config):\n",
    "        super().__init__()\n",
    "        self.trg_tokenizer = trg_tokenizer\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            input_dim,\n",
    "            config[\"hid_dim\"],\n",
    "            config[\"enc_layers\"],\n",
    "            config[\"enc_heads\"],\n",
    "            config[\"enc_pf_dim\"],\n",
    "            config[\"enc_dropout\"],\n",
    "        )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            output_dim,\n",
    "            config[\"hid_dim\"],\n",
    "            config[\"dec_layers\"],\n",
    "            config[\"dec_heads\"],\n",
    "            config[\"dec_pf_dim\"],\n",
    "            config[\"dec_dropout\"],\n",
    "        )\n",
    "\n",
    "        self.lr = config[\"lr\"]\n",
    "        self.apply(self.initialize_weights)\n",
    "    \n",
    "    \n",
    "    def initialize_weights(self, m):\n",
    "        if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "    \n",
    "    \n",
    "    # Training\n",
    "    # Use only when training and validation\n",
    "    def _forward(self, src, trg):\n",
    "        # src = list of Encoding([ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
    "        # trg = list of Encoding([ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
    "\n",
    "        # src_batch = [batch_size, src_len]\n",
    "        # src_mask  = [batch_size, 1, 1, src_len]\n",
    "        src_batch = torch.tensor([e.ids for e in src], device=self.device)\n",
    "        src_mask = torch.tensor([e.attention_mask for e in src], device=self.device).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        # trg_batch = [batch_size, trg_len-1]\n",
    "        # trg_mask  = [batch_size, 1, trg_len-1, trg_len-1]\n",
    "        trg_batch = torch.tensor([e.ids[:-1] for e in trg], device=self.device)\n",
    "        trg_pad_mask = torch.tensor([e.attention_mask[:-1] for e in trg], device=self.device).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        trg_len = trg_batch.shape[1]\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        \n",
    "        # enc_src = [batch_size, src_len, hid_dim]\n",
    "        enc_src = self.encoder(src_batch, src_mask)\n",
    "        \n",
    "        # output = [batch_size, trg_len, output_dim]\n",
    "        # attention = [batch_size, n_heads, trg_len, src_len]\n",
    "        output, attention = self.decoder(trg_batch, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        return output, attention\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # both are lists of encodings\n",
    "        src, trg = batch\n",
    "        \n",
    "        y = torch.tensor([e.ids for e in trg], device=self.device)\n",
    "        preds, _ = self._forward(src, trg)\n",
    "        # y    = [batch_size, trg_len]\n",
    "        # pred = [batch_size, trg_len-1, output_dim]\n",
    "        \n",
    "        output_dim = preds.shape[-1]\n",
    "        \n",
    "        # y    = [batch_size * (trg_len-1)]\n",
    "        # pred = [batch_size * (trg_len-1), output_dim]\n",
    "        y = y[:, 1:].contiguous().view(-1)\n",
    "        preds = preds.contiguous().view(-1, output_dim)\n",
    "        \n",
    "        loss = F.cross_entropy(preds, y, ignore_index=self.trg_tokenizer.token_to_id(\"[PAD]\"))\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        perplexity = torch.exp(loss)\n",
    "        self.log(\"train_ppl\", perplexity)\n",
    "        \n",
    "        if self.global_step % 100 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, trg = batch\n",
    "        y = torch.tensor([e.ids for e in trg], device=self.device)\n",
    "        preds, _ = self._forward(src, trg)\n",
    "        \n",
    "        output_dim = preds.shape[-1]\n",
    "        y = y[:, 1:].contiguous().view(-1)\n",
    "        preds = preds.contiguous().view(-1, output_dim)\n",
    "        \n",
    "        loss = F.cross_entropy(preds, y, ignore_index=self.trg_tokenizer.token_to_id(\"[PAD]\"))\n",
    "        self.log(\"valid_loss\", loss, sync_dist=True)\n",
    "        \n",
    "        perplexity = torch.exp(loss)\n",
    "        self.log(\"valid_ppl\", perplexity, sync_dist=True)\n",
    "        \n",
    "    \n",
    "    # Inference\n",
    "    # * Let you use the pl model as a pytorch model.\n",
    "    # * \n",
    "    # * pl_model.eval()\n",
    "    # * pl_model(X)\n",
    "    # *\n",
    "    def forward(self, src, max_len=100):\n",
    "        # src_batch    = [batch_size, src_len]\n",
    "        # src_mask     = [batch_size, 1, 1, src_len]\n",
    "        # real_src_len = [batch_size] (src_len without <pad>)\n",
    "        src_batch = torch.tensor([e.ids for e in src], device=self.device)\n",
    "        src_mask = torch.tensor([e.attention_mask for e in src], device=self.device).unsqueeze(1).unsqueeze(2)\n",
    "        batch_size = src_batch.shape[0]\n",
    "        \n",
    "        # first input to the decoder = [BOS] tokens\n",
    "        # trg_batch = [batch_size, 1]\n",
    "        trg_batch = torch.tensor([self.trg_tokenizer.token_to_id(\"[BOS]\")], device=self.device).repeat(batch_size).unsqueeze(1)\n",
    "        \n",
    "        # enc_src = [batch_size, src_len, hid_dim]\n",
    "        enc_srctrg_pad_idxoder(src_batch, src_mask)\n",
    "        \n",
    "        for _ in range(1, max_len):\n",
    "            trg_pad_mask = (trg_batch != self.trg_tokenizer.token_to_id(\"[PAD]\")).unsqueeze(1).unsqueeze(2)\n",
    "            trg_sub_mask = torch.tril(torch.ones((trg_batch.shape[1], trg_batch.shape[1]), device = self.device)).bool()\n",
    "            trg_mask = trg_pad_mask & trg_sub_mask\n",
    "            # trg_mask = [batch_size, 1, trg_len, trg_len]\n",
    "            \n",
    "            # output = [batch_size, trg_len, output_dim]\n",
    "            # attention = [batch_size, n_heads, trg_len, src_len]\n",
    "            output, attention = self.decoder(trg_batch, enc_src, trg_mask, src_mask)\n",
    "            pred = output.argmax(2)[:, -1].unsqueeze(1)\n",
    "            \n",
    "            trg_batch = torch.cat([trg_batch, pred], dim=1)\n",
    "        \n",
    "        real_src_len = torch.sum(src_mask, axis=3).view(-1)\n",
    "\n",
    "        return trg_batch, attention, real_src_len\n",
    "        \n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        src, trg = batch\n",
    "        \n",
    "        output, attn_matrix = self._forward(src, trg)\n",
    "        preds = output.argmax(2)\n",
    "        src_mask = torch.tensor([e.attention_mask for e in src], device=self.device)\n",
    "        real_src_len = torch.sum(src_mask, axis=1).view(-1)\n",
    "        \n",
    "        # attn_matrix  = [batch_size, n_heads, trg_len, src_len]\n",
    "        # preds        = [batch_size, trg_len]\n",
    "        # real_src_len = [batch_size]\n",
    "        \n",
    "        # convert `preds` tensor to list of real sentences (tokens)\n",
    "        # meaning to cut the sentence by [EOS] and remove the [PAD] tokens\n",
    "        \n",
    "        # eos_pos = dict(sentence_idx: first_pad_position)\n",
    "        #\n",
    "        # e.g., {0: 32, 2: 55} \n",
    "        # Meaning that we have 32 tokens (include [EOS]) in the first predicted sentence\n",
    "        # and `max_len` tokens (no [EOS]) in the second predicted setence\n",
    "        # and 55 tokens (include [EOS]) in the third predicted sentence\n",
    "        eos_pos = dict(reversed((preds == self.trg_tokenizer.token_to_id(\"[EOS]\")).nonzero().tolist()))\n",
    "    \n",
    "        pred_sentences, attn_matrices = [], []\n",
    "        for idx, (sentence, attention, src_len) in enumerate(zip(preds, attn_matrix, real_src_len)):\n",
    "            \n",
    "            # sentence  = [trg_len_with_pad]\n",
    "            #           = [real_trg_len]\n",
    "            pred_sentences.append(sentence[:eos_pos.get(idx)+1 if eos_pos.get(idx) else None])\n",
    "            \n",
    "            # attention = [n_heads, trg_len_with_pad, src_len_with_pad]\n",
    "            #           = [n_heads, real_trg_len, real_src_len]\n",
    "            attn_matrices.append(attention[:, :eos_pos.get(idx)+1 if eos_pos.get(idx) else None, :src_len])\n",
    "        \n",
    "        # source sentences for displaying attention matrix \n",
    "        src = [[token for token in e.tokens if token != \"[PAD]\"] for e in src]\n",
    "        \n",
    "        # target sentences for calculating BLEU scores\n",
    "        trg = [[token for token in e.tokens if token != \"[PAD]\"] for e in trg]\n",
    "        \n",
    "        return pred_sentences, attn_matrices, src, trg\n",
    "        \n",
    "    \n",
    "    def test_epoch_end(self, test_outputs):\n",
    "        outputs = []\n",
    "        for (pred_sent_list, attn_list, src_list, trg_list) in test_outputs:\n",
    "            for pred_sent, attn, src, trg in list(zip(pred_sent_list, attn_list, src_list, trg_list)):\n",
    "                pred_sent = list(map(self.trg_tokenizer.id_to_token, pred_sent))\n",
    "                outputs.append((pred_sent, attn, src, trg))\n",
    "        \n",
    "        # outputs = list of predictions of testsets, each has a tuple of (pred_sentence, attn_matrix, src_sentence, trg_sentence)\n",
    "        # pred_sentence = [trg_len]\n",
    "        # attn_matrix   = [n_heads, trg_len, src_len]\n",
    "        # src_sentence  = [src_len]\n",
    "        # trg_sentence  = [trg_len]\n",
    "        self.test_outputs = outputs\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=self.lr)\n",
    "    \n",
    "    \n",
    "    def optimizer_zero_grad(self, epoch, batch_idx, optimizer, optimizer_idx):\n",
    "        optimizer.zero_grad(set_to_none=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingFineTuning(pl.callbacks.BaseFinetuning):\r\n",
    "    def __init__(self, unfreeze_at_epoch=2):\r\n",
    "        super().__init__()\r\n",
    "        self._unfreeze_at_epoch = unfreeze_at_epoch\r\n",
    "\r\n",
    "    def freeze_before_training(self, pl_module):\r\n",
    "        # freeze any module you want\r\n",
    "        self.freeze(pl_module.encoder.tok_embedding)\r\n",
    "        self.freeze(pl_module.decoder.tok_embedding)\r\n",
    "\r\n",
    "    def finetune_function(self, pl_module, current_epoch, optimizer, optimizer_idx):\r\n",
    "        # When `current_epoch` is hit, embedding will start training.\r\n",
    "        if current_epoch == self._unfreeze_at_epoch:\r\n",
    "            self.unfreeze_and_add_param_group(\r\n",
    "                modules=[\r\n",
    "                    pl_module.encoder.tok_embedding,\r\n",
    "                    pl_module.decoder.tok_embedding,\r\n",
    "                ],\r\n",
    "                optimizer=optimizer,\r\n",
    "            )\r\n",
    "            \r\n",
    "embedding_finetune = EmbeddingFineTuning(unfreeze_at_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb_logger = pl.loggers.WandbLogger()\n",
    "\n",
    "model = Seq2SeqModel(\n",
    "    input_dim,\n",
    "    output_dim,\n",
    "    dm.trg_tokenizer,\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14,889,872 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:52: UserWarning: Checkpoint directory checkpoints exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = Path(\"checkpoints\")\r\n",
    "\r\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(dirpath=ckpt_dir,  # path for saving checkpoints\r\n",
    "                                          filename=f\"{job_name[job]}-{method_name[method]}-\" + \"{epoch}-{valid_loss:.3f}\",\r\n",
    "                                          monitor=\"valid_loss\",\r\n",
    "                                          mode=\"min\",\r\n",
    "                                          save_weights_only=True,\r\n",
    "                                          save_top_k=15,\r\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\r\n",
    "    fast_dev_run=False,\r\n",
    "    logger=wandb_logger,\r\n",
    "    gpus=1,\r\n",
    "    max_epochs=15,\r\n",
    "    gradient_clip_val=1,\r\n",
    "    precision=config[\"precision\"],\r\n",
    "    callbacks=[checkpoint, embedding_finetune],\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing (BLEU Scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corpus_bleu(preds: List[str], refs: List[List[str]], n_gram=4):\r\n",
    "    # arg example:\r\n",
    "    # preds: [\"机器人行业在环境问题上的措施\", \"松下生产科技公司也以环境先进企业为目标\"]\r\n",
    "    # refs: [[\"机器人在环境上的改变\", \"對於机器人在环境上的措施\"],  [\"松下科技公司的首要目标是解决环境问题\"]]\r\n",
    "    preds = list(map(list, preds))\r\n",
    "    refs = [[list(sen) for sen in ref] for ref in refs]\r\n",
    "    return torchmetrics.functional.nlp.bleu_score(preds, refs, n_gram=n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ckpt = {\r\n",
    "    \"baseline\": \"full_transformer_language_specific_baseline 52.78/transformer_language_specific_ch2jp-full-epoch=12-valid_loss=1.722-bleu=52.78.ckpt\",\r\n",
    "    \"semantic\": \"full_transformer_language_specific_semantic 52.83/transformer_language_specific_ch2jp-semantic-full-epoch=13-valid_loss=1.712-bleu=52.83.ckpt\",\r\n",
    "    \"phonetic\": \"full_transformer_language_specific_phonetic 53.04/transformer_language_specific_ch2jp-phonetic-full-epoch=12-valid_loss=1.689-bleu=53.04.ckpt\",\r\n",
    "    \"meta\": \"full_transformer_language_specific_meta 53.13/transformer_language_specific_ch2jp-meta-full-epoch=14-valid_loss=1.713-bleu=53.13.ckpt\",\r\n",
    "}\r\n",
    "\r\n",
    "pred_sentences = {}\r\n",
    "\r\n",
    "for filename, ckpt in test_ckpt.items():\r\n",
    "    model.load_state_dict(torch.load(ckpt_dir / ckpt)[\"state_dict\"])\r\n",
    "    trainer.test(model, datamodule=dm)\r\n",
    "    \r\n",
    "    preds = [\r\n",
    "        dm.trg_tokenizer.decode(list(map(dm.trg_tokenizer.token_to_id, output[0])))\r\n",
    "        for output in model.test_outputs\r\n",
    "    ]\r\n",
    "    refs = [\r\n",
    "        [dm.trg_tokenizer.decode(list(map(dm.trg_tokenizer.token_to_id, output[3])))]\r\n",
    "        for output in model.test_outputs\r\n",
    "    ]\r\n",
    "    \r\n",
    "    pred_sentences[filename] = preds\r\n",
    "\r\n",
    "pred_sentences[\"reference\"] = refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = [\r\n",
    "        [dm.src_tokenizer.decode(list(map(dm.src_tokenizer.token_to_id, output[2])))]\r\n",
    "        for output in model.test_outputs\r\n",
    "    ]\r\n",
    "pred_sentences[\"source\"] = srcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\r\n",
    "\r\n",
    "for i in tqdm(range(len(model.test_outputs))):\r\n",
    "    bleu = sentence_bleu(\r\n",
    "        model.test_outputs[i][0],\r\n",
    "        model.test_outputs[i][3],\r\n",
    "    )\r\n",
    "    scores.append(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(pred_sentences)[[\"source\", \"reference\", \"baseline\", \"semantic\", \"phonetic\", \"meta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bleu\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"pred_sentences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study and Attention Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Noto Sans CJK TC']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def sentence_bleu(pred_token, trg_token):\n",
    "    trg  = dm.trg_tokenizer.decode(list(map(dm.trg_tokenizer.token_to_id, trg_token)))\n",
    "    pred = dm.trg_tokenizer.decode(list(map(dm.trg_tokenizer.token_to_id, pred_token)))\n",
    "    return calculate_corpus_bleu([trg], [[pred]])\n",
    "\n",
    "\n",
    "def case_study(pred_token, src_token, trg_token, attn_matrix):\n",
    "    src  = dm.src_tokenizer.decode(list(map(dm.src_tokenizer.token_to_id, src_token)))\n",
    "    trg  = dm.trg_tokenizer.decode(list(map(dm.trg_tokenizer.token_to_id, trg_token)))\n",
    "    pred = dm.trg_tokenizer.decode(list(map(dm.trg_tokenizer.token_to_id, pred_token)))\n",
    "    bleu = calculate_corpus_bleu([trg], [[pred]])\n",
    "    \n",
    "    print(f\"SOURCE: \\n{src}\\n {'-'*100}\")\n",
    "    print(f\"TARGET: \\n{trg}\\n {'-'*100}\")\n",
    "    print(f\"PREDICTION: \\n{pred}\\n {'-'*100}\")\n",
    "    print(f\"BLEU SCORE: {bleu}\")\n",
    "    \n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i in range(6):\n",
    "        plt.subplot(3, 2, i+1)\n",
    "        ax = sns.heatmap(attn_matrix[i], xticklabels=src_token, yticklabels=pred_token)\n",
    "        ax.xaxis.set_ticks_position('top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2107/2107 [00:10<00:00, 203.38it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = []\r\n",
    "\r\n",
    "for i in tqdm(range(len(model.test_outputs))):\r\n",
    "    bleu = sentence_bleu(\r\n",
    "        model.test_outputs[i][0],\r\n",
    "        model.test_outputs[i][3],\r\n",
    "    )\r\n",
    "    scores.append(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor(0.2301),\n tensor(0.3042),\n tensor(0.6507),\n tensor(0.4098),\n tensor(0.2374),\n tensor(0.6076),\n tensor(0.3839),\n tensor(0.4338),\n tensor(0.3271),\n tensor(0.5029)]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[1020, 1023, 1140, 1271, 1399, 1400, 1403, 1405, 1471, 1525]"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heapq.nlargest(50, range(len(scores)), np.array(scores).take)[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: \n",
      "化学过程中爆炸灾害防止支援系统的开发\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "TARGET: \n",
      "化学プロセスにおける爆発災害防止支援システムの開発\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "PREDICTION: \n",
      "化学プロセスにおける爆発災害防止支援システムの開発\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "BLEU SCORE: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 21270 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 23398 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 36807 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 31243 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 20013 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 29190 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 28856 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 28798 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 23475 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 38450 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 27490 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 25903 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 25588 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 31995 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 32479 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 24320 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 21457 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 21270 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 23398 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 36807 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 31243 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 20013 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 29190 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 28856 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 28798 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 23475 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 38450 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 27490 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 25903 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 25588 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 31995 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 32479 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 24320 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 21457 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12503 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12525 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12475 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12473 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12395 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12362 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12369 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12427 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 30330 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 28797 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12471 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12486 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12512 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 12398 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 38283 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12503 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12525 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12475 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12473 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12395 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12362 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12369 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12427 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 30330 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 28797 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12471 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12486 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12512 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 12398 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 38283 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 2160x2160 with 12 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=1020\r\n",
    "case_study(model.test_outputs[i][0],\r\n",
    "           model.test_outputs[i][2],\r\n",
    "           model.test_outputs[i][3],\r\n",
    "           model.test_outputs[i][1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python388jvsc74a57bd0910af126f78e4f70975a50f5d0344a29878143e0b01cc32c99ca6cf65dbefcc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "910af126f78e4f70975a50f5d0344a29878143e0b01cc32c99ca6cf65dbefcc1"
   }
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}